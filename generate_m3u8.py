import os
import requests
from urllib.parse import quote
from bs4 import BeautifulSoup

# ===================== å°æ ‡é…ç½®ï¼ˆé€‚é…GitHubä»£ç†ï¼‰ =====================
# GitHubä»£ç†åœ°å€
GITHUB_PROXY = "https://ghfast.top/"
# åŸå§‹å°æ ‡ä»“åº“åœ°å€
RAW_LOGO_BASE = "https://github.com/iptv-org/logos/raw/master/logos/"
# å¸¦ä»£ç†çš„å°æ ‡åŸºç¡€åœ°å€
BASE_LOGO_URL = GITHUB_PROXY + RAW_LOGO_BASE
# é»˜è®¤å°æ ‡ï¼ˆå¸¦ä»£ç†ï¼‰
DEFAULT_LOGO = GITHUB_PROXY + "https://github.com/iptv-org/logos/raw/master/logos/default.png"

# ç‰¹æ®Šé¢‘é“å°æ ‡æ˜ å°„ï¼ˆè‡ªåŠ¨é€‚é…ä»£ç†ï¼‰
SPECIAL_LOGO_MAPPING = {
    "CCTV-å°‘å„¿": f"{RAW_LOGO_BASE}cctv-14.png",
    "CCTV-17": f"{RAW_LOGO_BASE}cctv-17.png",
    "CCTV-5ï¼‹": f"{RAW_LOGO_BASE}cctv-5plus.png",
    "CGTNè‹±è¯­": f"{RAW_LOGO_BASE}cgtn.png",
    "å››å·å«è§†": f"{RAW_LOGO_BASE}sichuan.png",
    "æ¹–å—å«è§†": f"{RAW_LOGO_BASE}hunan.png",
    "æ±Ÿè‹å«è§†": f"{RAW_LOGO_BASE}jiangsu.png",
    "æµ™æ±Ÿå«è§†": f"{RAW_LOGO_BASE}zhejiang.png",
    "ä¸œæ–¹å«è§†": f"{RAW_LOGO_BASE}dragon-tv.png",
    "åŒ—äº¬å«è§†": f"{RAW_LOGO_BASE}beijing.png",
    "å¹¿ä¸œå«è§†": f"{RAW_LOGO_BASE}guangdong.png",
    "æ·±åœ³å«è§†": f"{RAW_LOGO_BASE}shenzhen.png",
    "å¤©æ´¥å«è§†": f"{RAW_LOGO_BASE}tianjin.png",
    "å±±ä¸œå«è§†": f"{RAW_LOGO_BASE}shandong.png",
    "å®‰å¾½å«è§†": f"{RAW_LOGO_BASE}anhui.png",
    "è¾½å®å«è§†": f"{RAW_LOGO_BASE}liaoning.png",
    "é»‘é¾™æ±Ÿå«è§†": f"{RAW_LOGO_BASE}heilongjiang.png",
    "å‰æ—å«è§†": f"{RAW_LOGO_BASE}jilin.png",
    "æ²³å—å«è§†": f"{RAW_LOGO_BASE}henan.png",
    "æ¹–åŒ—å«è§†": f"{RAW_LOGO_BASE}hubei.png",
    "æ±Ÿè¥¿å«è§†": f"{RAW_LOGO_BASE}jiangxi.png",
    "å¹¿è¥¿å«è§†": f"{RAW_LOGO_BASE}guangxi.png",
    "äº‘å—å«è§†": f"{RAW_LOGO_BASE}yunnan.png",
    "è´µå·å«è§†": f"{RAW_LOGO_BASE}guizhou.png",
    "å±±è¥¿å«è§†": f"{RAW_LOGO_BASE}shanxi.png",
    "é™•è¥¿å«è§†": f"{RAW_LOGO_BASE}shaanxi.png",
    "é’æµ·å«è§†": f"{RAW_LOGO_BASE}qinghai.png",
    "å®å¤å«è§†": f"{RAW_LOGO_BASE}ningxia.png",
    "å†…è’™å¤å«è§†": f"{RAW_LOGO_BASE}neimenggu.png",
    "è¥¿è—å«è§†": f"{RAW_LOGO_BASE}tibet.png",
    "æ–°ç–†å«è§†": f"{RAW_LOGO_BASE}xinjiang.png",
    "ç”˜è‚ƒå«è§†": f"{RAW_LOGO_BASE}gansu.png",
    "æµ·å—å«è§†": f"{RAW_LOGO_BASE}hainan.png",
    "å…µå›¢å«è§†": f"{RAW_LOGO_BASE}bingtuan.png",
    "ä¸œå—å«è§†": f"{RAW_LOGO_BASE}fujian.png",
    "å»¶è¾¹å«è§†": f"{RAW_LOGO_BASE}yanbian.png",
    "åº·å·´å«è§†": f"{RAW_LOGO_BASE}kangba.png",
    "CDTV-1": f"{RAW_LOGO_BASE}chengdu.png"
}

# ===================== æ ¸å¿ƒé…ç½®é¡¹ =====================
# 1. è¿‡æ»¤ç”»ä¸­ç”»é¢‘é“çš„å…³é”®è¯
FILTER_KEYWORDS = ["ç”»ä¸­ç”»", "PIP", "pip", "ç”»ä¸­", "ä¸­ç”»"]

# 2. udpxyåœ°å€ä¸è¾“å‡ºæ–‡ä»¶çš„æ˜ å°„
UDPXY_CONFIGS = [
    {"udpxy_url": "http://192.168.16.254:8866", "output_file": "iptv.m3u8"},
    {"udpxy_url": "http://192.168.19.254:8866", "output_file": "iptv-t.m3u8"}
]

# 3. æ•°æ®æºå’ŒEPGé…ç½®
SOURCE_URL = "https://epg.51zmt.top:8001/multicast/"
EPG_URL = "http://epg.51zmt.top:8000/e.xml.gz"

# ===================== åŠŸèƒ½å‡½æ•° =====================
def get_channel_group(channel_name):
    """æ ¹æ®é¢‘é“åç§°åˆ¤æ–­æ‰€å±åˆ†ç»„"""
    if channel_name.startswith("CCTV") or channel_name.startswith("CGTN"):
        return "å¤®è§†"
    elif any(prefix in channel_name for prefix in ["SCTV", "CDTV", "åº·å·´å«è§†", "å³¨çœ‰ç”µå½±", "å››å·ä¹¡æ‘"]):
        return "åœ°æ–¹å°-å››å·"
    elif any(suffix in channel_name for suffix in ["å«è§†", "æ¹–å—å«è§†", "æ±Ÿè‹å«è§†", "æµ™æ±Ÿå«è§†"]):
        return "çœçº§å«è§†"
    elif "4K" in channel_name or "ä¸“åŒº" in channel_name:
        return "4Kä¸“åŒº"
    else:
        return "å…¶ä»–é¢‘é“"

def get_channel_logo(channel_name):
    """æ ¹æ®é¢‘é“åè·å–å¸¦ä»£ç†çš„å°æ ‡URL"""
    # 1. ä¼˜å…ˆåŒ¹é…ç‰¹æ®Šé¢‘é“æ˜ å°„ï¼ˆæ‹¼æ¥ä»£ç†ï¼‰
    if channel_name in SPECIAL_LOGO_MAPPING:
        raw_logo_url = SPECIAL_LOGO_MAPPING[channel_name]
        return GITHUB_PROXY + raw_logo_url
    
    # 2. é€šç”¨åŒ¹é…ï¼šå»é™¤åç¼€ï¼Œè½¬å°å†™ï¼Œæ‹¼æ¥ä»£ç†
    clean_name = channel_name.replace("é«˜æ¸…", "").replace("4K", "").replace("ï¼‹", "plus").strip()
    if clean_name.startswith("CCTV"):
        logo_name = clean_name.lower()
    else:
        logo_name = clean_name.lower().replace(" ", "-")
    
    # 3. æ‹¼æ¥åŸå§‹URL + ä»£ç†
    raw_logo_url = f"{RAW_LOGO_BASE}{logo_name}.png"
    proxy_logo_url = GITHUB_PROXY + raw_logo_url
    
    # 4. å…œåº•ï¼šè¿”å›å¸¦ä»£ç†çš„é»˜è®¤å°æ ‡
    return proxy_logo_url

def get_multicast_html(url):
    """è·å–ç»„æ’­æºçš„HTMLé¡µé¢"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, verify=False, timeout=30, headers=headers)
        response.raise_for_status()
        response.encoding = 'utf-8'
        return response.text
    except Exception as e:
        print(f"è·å–HTMLé¡µé¢å¤±è´¥: {e}")
        raise

def parse_multicast_table(html_content):
    """è§£æHTMLä¸­çš„ç»„æ’­è¡¨æ ¼ï¼Œè¿‡æ»¤ç”»ä¸­ç”»é¢‘é“"""
    soup = BeautifulSoup(html_content, 'html.parser')
    table = soup.find('table')
    if not table:
        raise ValueError("æœªæ‰¾åˆ°é¢‘é“è¡¨æ ¼")
    
    channels = []
    filtered_count = 0
    rows = table.find('tbody').find_all('tr')
    
    for row in rows:
        cells = row.find_all('td')
        if len(cells) < 3:
            continue
        
        channel_name = cells[1].text.strip()
        multicast_addr = cells[2].text.strip()
        
        # è¿‡æ»¤ç”»ä¸­ç”»é¢‘é“
        if any(keyword in channel_name for keyword in FILTER_KEYWORDS):
            filtered_count += 1
            continue
        
        if not channel_name or not multicast_addr:
            continue
        
        logo = get_channel_logo(channel_name)
        tvg_id = channel_name.replace('é«˜æ¸…', '').replace('ï¼‹', 'plus').replace('-', '').replace('4K', '').lower()
        group = get_channel_group(channel_name)
        
        channels.append({
            'name': channel_name,
            'multicast': multicast_addr,
            'logo': logo,
            'tvg_id': tvg_id,
            'group': group
        })
    
    print(f"âœ… è§£æå®Œæˆï¼šå…±è¯†åˆ« {len(channels) + filtered_count} ä¸ªé¢‘é“ï¼Œè¿‡æ»¤ {filtered_count} ä¸ªç”»ä¸­ç”»é¢‘é“ï¼Œä¿ç•™ {len(channels)} ä¸ªæœ‰æ•ˆé¢‘é“")
    return channels

def generate_m3u8(channels, udpxy_url, output_file):
    """ç”Ÿæˆå•ä¸ªm3u8æ–‡ä»¶"""
    # M3U8å¤´éƒ¨ï¼ˆå«æ­£ç¡®çš„EPGåœ°å€ï¼‰
    m3u8_header = f"""#EXTM3U x-tvg-url="{EPG_URL}"
"""
    m3u8_lines = [m3u8_header]

    # æŒ‰åˆ†ç»„å½’ç±»é¢‘é“
    grouped_channels = {}
    for channel in channels:
        group = channel['group']
        grouped_channels[group] = grouped_channels.get(group, []) + [channel]
    
    # åˆ†ç»„æ˜¾ç¤ºé¡ºåº
    group_order = ["å¤®è§†", "çœçº§å«è§†", "åœ°æ–¹å°-å››å·", "4Kä¸“åŒº", "å…¶ä»–é¢‘é“"]
    for group in grouped_channels.keys():
        if group not in group_order:
            group_order.append(group)
    
    # ç”Ÿæˆm3u8å†…å®¹
    for group in group_order:
        if group not in grouped_channels:
            continue
        m3u8_lines.append(f"#EXTGRP:{group}")
        m3u8_lines.append("")
        for channel in grouped_channels[group]:
            name = channel['name']
            multicast = channel['multicast']
            logo = channel['logo']
            tvg_id = channel['tvg_id']
            
            multicast_parts = multicast.split(":")
            if len(multicast_parts) != 2:
                print(f"âš ï¸  è·³è¿‡æ— æ•ˆåœ°å€ {multicast}ï¼ˆé¢‘é“ï¼š{name}ï¼‰")
                continue
            ip, port = multicast_parts
            udpxy_play_url = f"{udpxy_url.rstrip('/')}/udp/{ip}:{port}"
            
            channel_line = f"""#EXTINF:-1 tvg-id="{tvg_id}" tvg-logo="{logo}",{name}
{udpxy_play_url}
"""
            m3u8_lines.append(channel_line)
    
    # ä¿å­˜æ–‡ä»¶
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("".join(m3u8_lines))
    
    # ç»Ÿè®¡åˆ†ç»„ä¿¡æ¯
    group_stats = {g:len(c) for g,c in grouped_channels.items()}
    print(f"\nğŸ“„ ç”Ÿæˆæ–‡ä»¶ï¼š{output_file}ï¼ˆudpxyï¼š{udpxy_url}ï¼‰")
    print(f"ğŸ“Š åˆ†ç»„ç»Ÿè®¡ï¼š{group_stats}")
    return output_file

def main():
    """ä¸»å‡½æ•°ï¼šæ‰¹é‡ç”Ÿæˆå¤šudpxyåœ°å€çš„m3u8æ–‡ä»¶"""
    try:
        # 1. è·å–å¹¶è§£ææ•°æ®æºï¼ˆåªè§£æä¸€æ¬¡ï¼Œå¤ç”¨é¢‘é“æ•°æ®ï¼‰
        print(f"ğŸ” å¼€å§‹è·å–æ•°æ®æºï¼š{SOURCE_URL}")
        html_content = get_multicast_html(SOURCE_URL)
        channels = parse_multicast_table(html_content)
        
        if not channels:
            raise ValueError("âŒ æœªè§£æåˆ°ä»»ä½•æœ‰æ•ˆé¢‘é“æ•°æ®")
        
        # 2. å¾ªç¯ç”Ÿæˆæ¯ä¸ªudpxyå¯¹åº”çš„æ–‡ä»¶
        print("\nğŸš€ å¼€å§‹ç”Ÿæˆm3u8æ–‡ä»¶ï¼š")
        print(f"ğŸ–¼ï¸  å°æ ‡ä»£ç†åœ°å€ï¼š{GITHUB_PROXY}")
        generated_files = []
        for config in UDPXY_CONFIGS:
            udpxy_url = config["udpxy_url"]
            output_file = config["output_file"]
            generated_file = generate_m3u8(channels, udpxy_url, output_file)
            generated_files.append(generated_file)
        
        # 3. è¾“å‡ºæœ€ç»ˆç»“æœ
        print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨ï¼š")
        for file in generated_files:
            print(f"  - {file}")
        print(f"ğŸ“¡ EPGæºåœ°å€ï¼š{EPG_URL}")
        print(f"ğŸ–¼ï¸  å°æ ‡æºï¼šiptv-orgå…¬å¼€åº“ï¼ˆä»£ç†ï¼š{GITHUB_PROXY}ï¼‰")
    
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
        # ç”Ÿæˆé”™è¯¯å…œåº•æ–‡ä»¶
        for config in UDPXY_CONFIGS:
            with open(config["output_file"], "w", encoding="utf-8") as f:
                f.write(f"#EXTM3U\n# ç”Ÿæˆå¤±è´¥ï¼š{str(e)}\n")
        raise

if __name__ == "__main__":
    main()
